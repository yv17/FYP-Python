{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tensorflow\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_train = np.load('voxel_train.npy')\n",
    "gt_train = np.load('gt_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Loss functions\n",
    "\n",
    "arr=np.logspace(math.log10(10.0), math.log10(2000.), num=1, endpoint=True, base=10.0) # num = number of output\n",
    "\n",
    "arr=np.tile(arr, (2000, 1)) #(x,y) x = batch size\n",
    "\n",
    "arr_tf=tf.constant(arr.astype('float32'), dtype=tf.float32)\n",
    "\n",
    "#Implementation of the Wasserstein Distance\n",
    "def wasserstein_distance(y_actual,y_pred):\n",
    "\n",
    "    #np.abs(np.cumsum(gt_distributions[40,:]-dist_array[40,:])      \n",
    "    abs_cdf_difference=tf.math.abs(tf.math.cumsum(y_actual-y_pred,axis=1))\n",
    "\n",
    "    return tf.reduce_mean(0.5*tf.reduce_sum(tf.math.multiply(-arr_tf[:,:-1]+arr_tf[:,1:],abs_cdf_difference[:,:-1]+abs_cdf_difference[:,1:]),axis=1))\n",
    "\n",
    "#Combination loss function used in MIML\n",
    "def MSE_wasserstein_combo(y_actual,y_pred):\n",
    "\n",
    "    wass_loss=wasserstein_distance(y_actual,y_pred)\n",
    "    MSE= tf.math.reduce_mean(tf.reduce_mean(tf.math.squared_difference(y_pred, y_actual),axis=1))\n",
    "\n",
    "    return wass_loss+100000.*MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the network structure\n",
    "inputs = tf.keras.Input(shape=(6,)) #number of inputs\n",
    "x = tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(inputs)\n",
    "x = tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "x = tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "x = tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "x = tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "x = tf.keras.layers.Dense(256, activation=tf.nn.leaky_relu, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=tf.keras.activations.linear, kernel_initializer='he_uniform',bias_initializer=tf.keras.initializers.Constant(0.01))(x) # no. of outputs\n",
    "#outputs=tf.keras.layers.Dense(1, activation=tf.keras.activations.relu, kernel_initializer='normal',bias_initializer=tf.keras.initializers.Constant(0.1))(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define optimizer and train the network\n",
    "\n",
    "#To save the model for each epoch, uncomment the checkpoint_callback below\n",
    "# checkpoint_callback=tf.keras.callbacks.ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=True mode='auto', save_freq='epoch')\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# model.compile(optimizer=opt, loss=MSE_wasserstein_combo, metrics=['mse',wasserstein_distance])\n",
    "\n",
    "# start=time.time()\n",
    "\n",
    "# model.fit(signals_train, distributions_train,epochs=10, batch_size=10, validation_data=(signals_valid,distributions_valid))  # starts training\n",
    "\n",
    "# Original parameters\n",
    "# model.fit(signals_train, distributions_train,epochs=30, batch_size=2000, validation_data=(signals_valid,distributions_valid),callbacks=[checkpoint_callback])  # starts training\n",
    "\n",
    "\n",
    "# end=time.time()\n",
    "\n",
    "# print('Time Elapsed:%i seconds'%(end-start))"
   ]
  }
 ]
}